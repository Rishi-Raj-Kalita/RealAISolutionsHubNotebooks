{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "import os\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "\n",
    "def get_model(model: str = 'deepseek-r1:7b', provider: str = 'local'):\n",
    "    if (provider == 'local'):\n",
    "        from langchain_ollama import ChatOllama\n",
    "        llm = ChatOllama(model=model, temperature=0)\n",
    "        return llm\n",
    "    elif (provider == 'llama'):\n",
    "        # supports tools calling\n",
    "        from langchain_ollama import ChatOllama\n",
    "        llm = ChatOllama(model='llama3.1', temperature=0)\n",
    "        return llm\n",
    "    elif (provider == 'aws'):\n",
    "        from langchain_aws import ChatBedrockConverse\n",
    "        import boto3\n",
    "        access_key = os.getenv('ACCESS_KEY')\n",
    "        secret_key = os.getenv('SECRET_KEY')\n",
    "        bedrock_client = boto3.client('bedrock-runtime',\n",
    "                                      region_name='us-east-1',\n",
    "                                      aws_access_key_id=access_key,\n",
    "                                      aws_secret_access_key=secret_key)\n",
    "        llm = ChatBedrockConverse(client=bedrock_client,\n",
    "                                  model=model,\n",
    "                                  temperature=0)\n",
    "        return llm\n",
    "\n",
    "\n",
    "def get_embeddings(model:str='deepseek-r1:7b', provider:str='local'):\n",
    "    if(provider == 'local'):\n",
    "        from langchain_ollama import OllamaEmbeddings\n",
    "        embeddings=OllamaEmbeddings(model=model)\n",
    "        return embeddings\n",
    "    elif(provider == 'aws'):\n",
    "        from langchain_aws import BedrockEmbeddings\n",
    "        import boto3\n",
    "        access_key=os.getenv('ACCESS_KEY')\n",
    "        secret_key=os.getenv('SECRET_KEY')\n",
    "        bedrock_client=boto3.client('bedrock-runtime', region_name='us-east-1', aws_access_key_id=access_key, aws_secret_access_key=secret_key)\n",
    "        embeddings=BedrockEmbeddings(client=bedrock_client, model_id=model)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "model=get_model(provider='llama')\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    system_prompt = (\n",
    "        \"You are a helpful assistant. \"\n",
    "        \"Answer all questions to the best of your ability.\"\n",
    "    )\n",
    "    messages = [SystemMessage(content=system_prompt)] + state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the node and edge\n",
    "workflow.add_node(\"model\", call_model)\n",
    "workflow.add_edge(START, \"model\")\n",
    "\n",
    "# Add simple in-memory checkpointer\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Translate to French: I love programming.', additional_kwargs={}, response_metadata={}, id='fa4bd567-f31a-4d15-b3df-0b3f7a0b0c58'),\n",
       "  AIMessage(content='The translation is:\\n\\n\"J\\'adore le programmation.\"\\n\\nHowever, if you want to be more idiomatic and use a more common expression in French, you could say:\\n\\n\"Je suis passionné(e) par la programmation.\" (If you\\'re male)\\n\"Je suis passionnée par la programmation.\" (If you\\'re female)\\n\\nOr simply:\\n\"J\\'aime programmer.\"\\n\\nAll of these expressions convey the same idea: that you enjoy programming.', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-03-21T11:40:55.577499Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2655982208, 'load_duration': 33982250, 'prompt_eval_count': 39, 'prompt_eval_duration': 148618583, 'eval_count': 95, 'eval_duration': 2472230625, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-9a97310b-8ace-4f00-be11-1a9cacde1722-0', usage_metadata={'input_tokens': 39, 'output_tokens': 95, 'total_tokens': 134})]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Translate to French: I love programming.\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"1\"}},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Translate to French: I love programming.', additional_kwargs={}, response_metadata={}, id='fa4bd567-f31a-4d15-b3df-0b3f7a0b0c58'),\n",
       "  AIMessage(content='The translation is:\\n\\n\"J\\'adore le programmation.\"\\n\\nHowever, if you want to be more idiomatic and use a more common expression in French, you could say:\\n\\n\"Je suis passionné(e) par la programmation.\" (If you\\'re male)\\n\"Je suis passionnée par la programmation.\" (If you\\'re female)\\n\\nOr simply:\\n\"J\\'aime programmer.\"\\n\\nAll of these expressions convey the same idea: that you enjoy programming.', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-03-21T11:40:55.577499Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2655982208, 'load_duration': 33982250, 'prompt_eval_count': 39, 'prompt_eval_duration': 148618583, 'eval_count': 95, 'eval_duration': 2472230625, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, id='run-9a97310b-8ace-4f00-be11-1a9cacde1722-0', usage_metadata={'input_tokens': 39, 'output_tokens': 95, 'total_tokens': 134}),\n",
       "  HumanMessage(content='What did I just ask you?', additional_kwargs={}, response_metadata={}, id='09093921-8774-48d4-8541-83fc4ebe1f7f'),\n",
       "  AIMessage(content='You asked me to translate the phrase \"I love programming\" into French.', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-03-21T11:40:58.398301Z', 'done': True, 'done_reason': 'stop', 'total_duration': 665864917, 'load_duration': 26044959, 'prompt_eval_count': 150, 'prompt_eval_duration': 239742708, 'eval_count': 16, 'eval_duration': 398402250, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-d5ac4806-5734-4ab1-bb45-4977b0f5c16e-0', usage_metadata={'input_tokens': 150, 'output_tokens': 16, 'total_tokens': 166})]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What did I just ask you?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
